{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9063a4a-6d34-4c18-a0d3-f6a7a9f065cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig, Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e6c3ae-fca6-42f1-ace0-785b755def52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded 10000 notes.\n"
     ]
    }
   ],
   "source": [
    "# The project root directory is one level above the notebooks folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "dataset_path = os.path.join(project_root, \"dataset\", \"ner_data.json\")\n",
    "\n",
    "# Uploading data\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"âœ… Uploaded {len(data)} notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d89348-8ab4-4ba8-ac1b-a5c3e70f38ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-cased\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "texts = [item[\"sentence\"] for item in data]\n",
    "entities = [[(ent[\"start\"], ent[\"end\"], ent[\"label\"]) for ent in item[\"entities\"]] for item in data]\n",
    "\n",
    "tokenized_inputs = tokenizer(texts, padding=True, truncation=True, return_offsets_mapping=True)\n",
    "\n",
    "labels = []\n",
    "for i, offset_mapping in enumerate(tokenized_inputs.offset_mapping):\n",
    "    label = np.zeros(len(offset_mapping), dtype=int)\n",
    "    for start, end, _ in entities[i]:\n",
    "        for idx, (token_start, token_end) in enumerate(offset_mapping):\n",
    "            if token_start >= start and token_end <= end:\n",
    "                label[idx] = 1\n",
    "    labels.append(label)\n",
    "\n",
    "tokenized_inputs[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28db04d-017f-4856-bb0c-7ba95d6596ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging words in a sentence\n",
    "def shuffle_words(sentence):\n",
    "    words = sentence.split()\n",
    "    random.shuffle(words)\n",
    "    return ' '.join(words)\n",
    "    \n",
    "def synonym_replacement(sentence, num_synonyms=1):\n",
    "    words = sentence.split()\n",
    "    new_sentence = words.copy()\n",
    "\n",
    "    for _ in range(num_synonyms):\n",
    "        word_idx = random.randint(0, len(words)-1)\n",
    "        synonyms = wordnet.synsets(words[word_idx])\n",
    "        lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "        \n",
    "        if lemmas:\n",
    "            new_word = random.choice(list(lemmas))\n",
    "            new_sentence[word_idx] = new_word.replace(\"_\", \" \")\n",
    "\n",
    "    return \" \".join(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe8e461-d23b-4ec3-ae72-491db59dfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: There is a cat in the picture.\n",
      "Shuffled: the in a cat picture. There is\n",
      "Synonyms: There is a cat IN the picture.\n"
     ]
    }
   ],
   "source": [
    "example_sentence = \"There is a cat in the picture.\"\n",
    "print(\"Original:\", example_sentence)\n",
    "print(\"Shuffled:\", shuffle_words(example_sentence))\n",
    "print(\"Synonyms:\", synonym_replacement(example_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85cffc6e-2214-43eb-8058-a1123a04c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding augmentation to the training data\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "for text, label in zip(texts, labels):\n",
    "    # Adding original data\n",
    "    augmented_texts.append(text)\n",
    "    augmented_labels.append(label)\n",
    "    \n",
    "    # Let's add data with word shuffling\n",
    "    shuffled_text = shuffle_words(text)\n",
    "    augmented_texts.append(shuffled_text)\n",
    "    augmented_labels.append(label)\n",
    "\n",
    "tokenized_augmented = tokenizer(augmented_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data[\"input_ids\"]\n",
    "        self.attention_mask = tokenized_data[\"attention_mask\"]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Taking 30% of data\n",
    "_, texts_30, _, labels_30 = train_test_split(\n",
    "    augmented_texts, augmented_labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Dividing this 30% into training and test samples\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts_30, labels_30, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize separately for training and test data\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=50)\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=50)\n",
    "\n",
    "# Function that aligns the length of labels to tokens\n",
    "def align_labels(labels, encodings):\n",
    "    aligned_labels = []\n",
    "    for label, input_ids in zip(labels, encodings['input_ids']):\n",
    "        padded_label = np.zeros(len(input_ids), dtype=int)\n",
    "        length = min(len(label), len(input_ids))\n",
    "        padded_label[:length] = label[:length]\n",
    "        aligned_labels.append(padded_label)\n",
    "    return aligned_labels\n",
    "\n",
    "# Aligning the labels\n",
    "train_labels_aligned = align_labels(train_labels, train_encodings)\n",
    "test_labels_aligned = align_labels(test_labels, test_encodings)\n",
    "\n",
    "# Creating dataset\n",
    "train_dataset = NERDataset(train_encodings, train_labels_aligned)\n",
    "test_dataset = NERDataset(test_encodings, test_labels_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ede2cf-d6ee-462e-87c4-aac8703d455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\marko\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 08:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.093400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.060500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.03901118947399987, metrics={'train_runtime': 503.6698, 'train_samples_per_second': 28.59, 'train_steps_per_second': 1.787, 'total_flos': 73492368768000.0, 'train_loss': 0.03901118947399987, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "model_dir = os.path.join(project_root, \"NER\", \"model\")\n",
    "log_dir = os.path.join(model_dir, \"logs\")\n",
    "\n",
    "# Creating directories\n",
    "os.makedirs(r\"C:\\NER\\model\\logs\", exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=r\"C:\\NER\\model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=r\"C:\\NER\\model\\logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78dfd63d-ccbd-4a55-9d1e-c35dea30df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation Results:\n",
      "Precision: 0.9839\n",
      "Recall: 0.9899\n",
      "F1 Score: 0.9869\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "true_labels_flat = np.concatenate([item[\"labels\"].numpy().flatten() for item in test_dataset])\n",
    "pred_labels = preds.flatten()\n",
    "\n",
    "# Checking that the number of labels matches\n",
    "min_len = min(len(true_labels_flat), len(pred_labels))\n",
    "true_labels_flat = true_labels_flat[:min_len]\n",
    "pred_labels = pred_labels[:min_len]\n",
    "\n",
    "# Calculating metrics\n",
    "precision = precision_score(true_labels_flat, pred_labels, average=\"binary\")\n",
    "recall = recall_score(true_labels_flat, pred_labels, average=\"binary\")\n",
    "f1 = f1_score(true_labels_flat, pred_labels, average=\"binary\")\n",
    "\n",
    "print(f\"ðŸ“Š Evaluation Results:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d0a88e-d6b1-478f-becc-e95417b8a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model and tokenizer successfully saved.\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./NER/model\")\n",
    "tokenizer.save_pretrained(\"./NER/model\")\n",
    "print(\"âœ… Model and tokenizer successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da9e621-d314-4073-ae1e-584cfdc38429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Is there a horse in this picture?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999943, 'word': 'Is there a', 'start': 0, 'end': 10}, {'entity_group': 'LABEL_1', 'score': 0.9999182, 'word': 'horse', 'start': 11, 'end': 16}, {'entity_group': 'LABEL_0', 'score': 0.9999894, 'word': 'in this picture?', 'start': 17, 'end': 33}]\n",
      "\n",
      "Sentence: There might be a cow here.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999956, 'word': 'There might be a', 'start': 0, 'end': 16}, {'entity_group': 'LABEL_1', 'score': 0.99994636, 'word': 'cow', 'start': 17, 'end': 20}, {'entity_group': 'LABEL_0', 'score': 0.9999954, 'word': 'here.', 'start': 21, 'end': 26}]\n",
      "\n",
      "Sentence: Do you see a penguin in the image?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999951, 'word': 'Do you see a', 'start': 0, 'end': 12}, {'entity_group': 'LABEL_1', 'score': 0.99997604, 'word': 'penguin', 'start': 13, 'end': 20}, {'entity_group': 'LABEL_0', 'score': 0.99999577, 'word': 'in the image?', 'start': 21, 'end': 34}]\n",
      "\n",
      "Sentence: I think there is a giraffe in the photo.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999958, 'word': 'I think there is a', 'start': 0, 'end': 18}, {'entity_group': 'LABEL_1', 'score': 0.9999772, 'word': 'giraffe', 'start': 19, 'end': 26}, {'entity_group': 'LABEL_0', 'score': 0.9999958, 'word': 'in the photo.', 'start': 27, 'end': 40}]\n",
      "\n",
      "Sentence: Can you spot a dolphin in this image?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.999995, 'word': 'Can you spot a', 'start': 0, 'end': 14}, {'entity_group': 'LABEL_1', 'score': 0.9999669, 'word': 'dolphin', 'start': 15, 'end': 22}, {'entity_group': 'LABEL_0', 'score': 0.9999953, 'word': 'in this image?', 'start': 23, 'end': 37}]\n",
      "\n",
      "Sentence: This picture definitely contains an elephant.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99999654, 'word': 'This picture definitely contains an', 'start': 0, 'end': 35}, {'entity_group': 'LABEL_1', 'score': 0.9999294, 'word': 'elephant', 'start': 36, 'end': 44}, {'entity_group': 'LABEL_0', 'score': 0.99999475, 'word': '.', 'start': 44, 'end': 45}]\n",
      "\n",
      "Sentence: Maybe there's a lion hidden here.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99999654, 'word': \"Maybe there ' s a\", 'start': 0, 'end': 15}, {'entity_group': 'LABEL_1', 'score': 0.99996424, 'word': 'lion', 'start': 16, 'end': 20}, {'entity_group': 'LABEL_0', 'score': 0.99999505, 'word': 'hidden here.', 'start': 21, 'end': 33}]\n",
      "\n",
      "Sentence: Is there a squirrel in the scene?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999943, 'word': 'Is there a', 'start': 0, 'end': 10}, {'entity_group': 'LABEL_1', 'score': 0.99994886, 'word': 'squirrel', 'start': 11, 'end': 19}, {'entity_group': 'LABEL_0', 'score': 0.99999493, 'word': 'in the scene?', 'start': 20, 'end': 33}]\n",
      "\n",
      "Sentence: Does this image feature a kangaroo?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99999493, 'word': 'Does this image feature a', 'start': 0, 'end': 25}, {'entity_group': 'LABEL_1', 'score': 0.9999766, 'word': 'kangaroo', 'start': 26, 'end': 34}, {'entity_group': 'LABEL_0', 'score': 0.9999937, 'word': '?', 'start': 34, 'end': 35}]\n",
      "\n",
      "Sentence: Can we see a bear in this photo?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99999475, 'word': 'Can we see a', 'start': 0, 'end': 12}, {'entity_group': 'LABEL_1', 'score': 0.99996376, 'word': 'bear', 'start': 13, 'end': 17}, {'entity_group': 'LABEL_0', 'score': 0.9999958, 'word': 'in this photo?', 'start': 18, 'end': 32}]\n",
      "\n",
      "Sentence: There is a cat and a dog playing together in the picture.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99887085, 'word': 'There is a cat and a', 'start': 0, 'end': 20}, {'entity_group': 'LABEL_1', 'score': 0.9998635, 'word': 'dog', 'start': 21, 'end': 24}, {'entity_group': 'LABEL_0', 'score': 0.9999909, 'word': 'playing together in the picture.', 'start': 25, 'end': 57}]\n",
      "\n",
      "Sentence: Can you spot both a lion and a tiger here?\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.99778265, 'word': 'Can you spot both a lion and a', 'start': 0, 'end': 30}, {'entity_group': 'LABEL_1', 'score': 0.9998828, 'word': 'tiger', 'start': 31, 'end': 36}, {'entity_group': 'LABEL_0', 'score': 0.99999475, 'word': 'here?', 'start': 37, 'end': 42}]\n",
      "\n",
      "Sentence: I think there's a fox chasing a rabbit in this image.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999954, 'word': \"I think there ' s a\", 'start': 0, 'end': 17}, {'entity_group': 'LABEL_1', 'score': 0.9998281, 'word': 'fox', 'start': 18, 'end': 21}, {'entity_group': 'LABEL_0', 'score': 0.9661352, 'word': 'chasing a rabbit in this image.', 'start': 22, 'end': 53}]\n",
      "\n",
      "Sentence: This is a beautiful landscape.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999958, 'word': 'This is a beautiful', 'start': 0, 'end': 19}, {'entity_group': 'LABEL_1', 'score': 0.83379954, 'word': 'landscape', 'start': 20, 'end': 29}, {'entity_group': 'LABEL_0', 'score': 0.9999968, 'word': '.', 'start': 29, 'end': 30}]\n",
      "\n",
      "Sentence: I see some buildings and trees.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.8767348, 'word': 'I see some buildings', 'start': 0, 'end': 20}, {'entity_group': 'LABEL_1', 'score': 0.66246575, 'word': 'and', 'start': 21, 'end': 24}, {'entity_group': 'LABEL_0', 'score': 0.9999291, 'word': 'trees.', 'start': 25, 'end': 31}]\n",
      "\n",
      "Sentence: This image shows a car on a road.\n",
      "Results: [{'entity_group': 'LABEL_0', 'score': 0.9999944, 'word': 'This image shows a', 'start': 0, 'end': 18}, {'entity_group': 'LABEL_1', 'score': 0.99970394, 'word': 'car', 'start': 19, 'end': 22}, {'entity_group': 'LABEL_0', 'score': 0.99559474, 'word': 'on a road.', 'start': 23, 'end': 33}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uploading model for NER\n",
    "ner_pipeline = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"./NER/model\",\n",
    "    tokenizer=\"./NER/model\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "# New examples for testing\n",
    "examples = [\n",
    "    \"Is there a horse in this picture?\",\n",
    "    \"There might be a cow here.\",\n",
    "    \"Do you see a penguin in the image?\",\n",
    "    \"I think there is a giraffe in the photo.\",\n",
    "    \"Can you spot a dolphin in this image?\",\n",
    "    \"This picture definitely contains an elephant.\",\n",
    "    \"Maybe there's a lion hidden here.\",\n",
    "    \"Is there a squirrel in the scene?\",\n",
    "    \"Does this image feature a kangaroo?\",\n",
    "    \"Can we see a bear in this photo?\",\n",
    "    \"There is a cat and a dog playing together in the picture.\",\n",
    "    \"Can you spot both a lion and a tiger here?\",\n",
    "    \"I think there's a fox chasing a rabbit in this image.\",\n",
    "    \"This is a beautiful landscape.\",\n",
    "    \"I see some buildings and trees.\",\n",
    "    \"This image shows a car on a road.\"\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    results = ner_pipeline(example)\n",
    "    print(f\"Sentence: {example}\\nResults: {results}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bbc58-236f-44a4-b053-089d3b90ef44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
